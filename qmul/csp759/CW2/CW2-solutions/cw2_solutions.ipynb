{"cells":[{"cell_type":"markdown","metadata":{"id":"kT2CO3WQ_uZc"},"source":["# Neural networks for Classification - FashionMNIST"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ukiRwCrB-A9"},"outputs":[],"source":["# Install latest Tensorflow build\n","!pip install tensorflow\n","from tensorflow import summary\n","%load_ext tensorboard\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","\n","train_set = torchvision.datasets.FashionMNIST(root = \".\", train=True, download=True, transform=transforms.ToTensor())\n","test_set = torchvision.datasets.FashionMNIST(root = \".\", train=False, download=True, transform=transforms.ToTensor())\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False)\n","torch.manual_seed(0)\n","# If you are using CuDNN , otherwise you can just ignore\n","torch.cuda.manual_seed(0)\n","torch.backends.cudnn.deterministic=True\n","torch.backends.cudnn.benchmark=False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lZ7ggePbDLdK"},"outputs":[],"source":["input_data, label = next(iter(train_loader))\n","plt.imshow(input_data[0,:,:,:].numpy().reshape(28,28), cmap=\"gray_r\");\n","print(\"Label is: {}\".format(label[0]))\n","print(\"Dimension of input data: {}\".format(input_data.size()))\n","print(\"Dimension of labels: {}\".format(label.size()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HYWt40a3DWg4"},"outputs":[],"source":["def init_weights(m):\n","    if isinstance(m, nn.Linear) or isinstance(m, torch.nn.Conv2d):\n","        torch.nn.init.xavier_uniform_(m.weight)\n","\n","# CNN implementation\n","\n","class MyCNN(nn.Module):\n","  def __init__(self):\n","    super(MyCNN, self).__init__()\n","    self.cnn_model = nn.Sequential(nn.Conv2d(1, 32, kernel_size=5), nn.ReLU(), nn.MaxPool2d(2), nn.Conv2d(32, 64, kernel_size=5), nn.ReLU(), nn.MaxPool2d(2))\n","    # self.fc_model = nn.Sequential(nn.Linear(1024, 1024), nn.ReLU(), nn.Linear(1024,256), nn.ReLU(), nn.Linear(256, 10))\n","    self.fc_model = nn.Sequential(nn.Linear(1024, 1024), nn.ReLU(), nn.Linear(1024,256), nn.ReLU(), nn.Dropout(0.3), nn.Linear(256, 10))\n","\n","    # self.cnn_model = nn.Sequential(nn.Conv2d(1, 32, kernel_size=5), nn.Tanh(), nn.MaxPool2d(2), nn.Conv2d(32, 64, kernel_size=5), nn.Tanh(), nn.MaxPool2d(2))\n","    # self.fc_model = nn.Sequential(nn.Linear(1024, 1024), nn.Tanh(), nn.Linear(1024,256), nn.Tanh(), nn.Linear(256, 10))\n","\n","    # self.cnn_model = nn.Sequential(nn.Conv2d(1, 32, kernel_size=5), nn.Sigmoid(), nn.MaxPool2d(2), nn.Conv2d(32, 64, kernel_size=5), nn.Sigmoid(), nn.MaxPool2d(2))\n","    # self.fc_model = nn.Sequential(nn.Linear(1024, 1024), nn.Sigmoid(), nn.Linear(1024,256), nn.Sigmoid(), nn.Linear(256, 10))\n","\n","    # self.cnn_model = nn.Sequential(nn.Conv2d(1, 32, kernel_size=5), nn.ELU(), nn.MaxPool2d(2), nn.Conv2d(32, 64, kernel_size=5), nn.ELU(), nn.MaxPool2d(2))\n","    # self.fc_model = nn.Sequential(nn.Linear(1024, 1024), nn.ELU(), nn.Linear(1024,256), nn.ELU(), nn.Linear(256, 10))\n","\n","\n","  def forward(self, x):\n","    x = self.cnn_model(x)\n","    x = x.view(x.size(0), -1)\n","    x = self.fc_model(x)\n","    return x\n","\n","device = torch.device(\"cuda:0\")\n","\n","def evaluation(dataloader, loss_fn):\n","  total, correct = 0,0\n","  val_loss = 0\n","  net.eval()\n","  for data in dataloader:\n","    inputs, labels = data\n","    inputs, labels = inputs.to(device), labels.to(device)\n","    outputs = net(inputs)\n","    _, pred = torch.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (pred == labels).sum().item()\n","    loss = loss_fn(outputs, labels)\n","    val_loss += loss.item()\n","\n","  return val_loss, 100 * correct / total\n","\n","# for alpha in [0.001, 0.1, 0.5, 1, 10]:\n","for alpha in [0.1]:\n","\n","    print(alpha)\n","\n","    net = MyCNN().to(device)\n","    net.apply(init_weights)\n","    loss_fn = nn.CrossEntropyLoss()\n","    loss_fn.to(device)\n","    opt = torch.optim.SGD(list(net.parameters()), lr=alpha)\n","\n","    loss_epoch_array = []\n","    max_epochs = 30\n","    loss_epoch = 0\n","    train_accuracy = []\n","    valid_accuracy = []\n","    for epoch in range(max_epochs):\n","      loss_epoch = 0\n","      for i, data in enumerate(train_loader, 0):\n","        net.train()\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        opt.zero_grad()\n","        outputs = net(inputs)\n","        loss = loss_fn(outputs, labels)\n","        loss.backward()\n","        opt.step()\n","        loss_epoch += loss.item()\n","      loss_epoch_array.append(loss_epoch)\n","      _, train_acc = evaluation(train_loader, loss_fn)\n","      train_accuracy.append(train_acc)\n","      val_loss, val_acc = evaluation(test_loader, loss_fn)\n","      valid_accuracy.append(val_acc)\n","      print(epoch + 1, loss_epoch_array[-1], train_accuracy[-1], val_loss, valid_accuracy[-1])"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}