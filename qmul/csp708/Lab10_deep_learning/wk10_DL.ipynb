{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Introduction\n",
        "\n",
        "In this lab we will use [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset,"
      ],
      "metadata": {
        "id": "sAX9uzRGQdRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "FEYdgwBpP02I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enabling and testing the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Edit→Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with pytorch:"
      ],
      "metadata": {
        "id": "dVOtNiLzPw4u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_pi3NOjxVrQ"
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the dataset\n",
        "\n",
        "Read the code below and understand what it does. \n",
        "\n",
        "We are using the built-in dataset for CIFAR10, and we are applying a set of transformations to avoid overfitting."
      ],
      "metadata": {
        "id": "4wr2x2eXp_3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "metadata": {
        "id": "dUM8_XeOSzGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # de-normalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images[:10]))\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(10)))"
      ],
      "metadata": {
        "id": "las1WRq2o_ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AlexNet\n",
        "\n",
        "We will use AlexNet[1] architecture to train on this task.\n",
        "\n",
        "\n",
        "We have loaded the architecture from torch hub and you can review the model architecture below."
      ],
      "metadata": {
        "id": "sMTYmPSEp96l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.alexnet(num_classes=10)\n",
        "model"
      ],
      "metadata": {
        "id": "1YjwZhzQrWXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will train the network using Stochastic Gradient Descent ([SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)).\n",
        "\n",
        "Create the optimizer below, make sure an appropriate weight decay, momentum and lr are selected.\n"
      ],
      "metadata": {
        "id": "iomalGC7sXJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here"
      ],
      "metadata": {
        "id": "-HaZ-s_aswmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now create a training loop (using previous labs as example or by looking into pytorch documentation) and train the network for 10 epochs on the train set. Produce a confusion matrix for the test set predictions."
      ],
      "metadata": {
        "id": "SFLytEwws4pV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here"
      ],
      "metadata": {
        "id": "FHojwkE8syUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "We will try this, using transfer learning and fine-tuning. Specifically, we will use the AlexNet architecture pre-trained on ImageNet and will fine-tune the classifier."
      ],
      "metadata": {
        "id": "xUe9VzbetVM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained = models.alexnet(weights='DEFAULT')\n",
        "model = models.alexnet(num_classes=10)\n",
        "model.load_state_dict(pretrained.features.state_dict(), strict=False)\n",
        "for param in model.features.parameters():\n",
        "    param.require_grad=False"
      ],
      "metadata": {
        "id": "usYsPhHGvNhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We loaded the pretrained weights on the feature extraction part of the architecture and have frozen them, so that they do not update during training.\n",
        "\n",
        "Create a new optimizer and repeat the training process for the new model. Then produce a confusion matrix for the new model and compare the results with training from scratch."
      ],
      "metadata": {
        "id": "l-oaOQ_cwwXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here"
      ],
      "metadata": {
        "id": "SZgt8f81x8E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unsupervised tasks\n",
        "\n",
        "During the lecture you went through some unsupervised paradigms for deep learning. In this section, we will expand on contrastive learning [2],[3] using a supervised contrastive approach [4] and then evaluate the performance on the downstream task."
      ],
      "metadata": {
        "id": "2RVOHq5yV-HN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code borrowed from https://github.com/HobbitLong/SupContrast\n",
        "class SupConLoss(nn.Module):\n",
        "    \"\"\"Supervised Contrastive Learning: https://arxiv.org/pdf/2004.11362.pdf.\n",
        "    It also supports the unsupervised contrastive loss in SimCLR\"\"\"\n",
        "    def __init__(self, temperature=0.07, contrast_mode='all',\n",
        "                 base_temperature=0.07):\n",
        "        super(SupConLoss, self).__init__()\n",
        "        self.temperature = temperature\n",
        "        self.contrast_mode = contrast_mode\n",
        "        self.base_temperature = base_temperature\n",
        "\n",
        "    def forward(self, features, labels=None, mask=None):\n",
        "        \"\"\"Compute loss for model. If both `labels` and `mask` are None,\n",
        "        it degenerates to SimCLR unsupervised loss:\n",
        "        https://arxiv.org/pdf/2002.05709.pdf\n",
        "        Args:\n",
        "            features: hidden vector of shape [bsz, n_views, ...].\n",
        "            labels: ground truth of shape [bsz].\n",
        "            mask: contrastive mask of shape [bsz, bsz], mask_{i,j}=1 if sample j\n",
        "                has the same class as sample i. Can be asymmetric.\n",
        "        Returns:\n",
        "            A loss scalar.\n",
        "        \"\"\"\n",
        "        device = (torch.device('cuda')\n",
        "                  if features.is_cuda\n",
        "                  else torch.device('cpu'))\n",
        "\n",
        "        if len(features.shape) < 3:\n",
        "            raise ValueError('`features` needs to be [bsz, n_views, ...],'\n",
        "                             'at least 3 dimensions are required')\n",
        "        if len(features.shape) > 3:\n",
        "            features = features.view(features.shape[0], features.shape[1], -1)\n",
        "\n",
        "        batch_size = features.shape[0]\n",
        "        if labels is not None and mask is not None:\n",
        "            raise ValueError('Cannot define both `labels` and `mask`')\n",
        "        elif labels is None and mask is None:\n",
        "            mask = torch.eye(batch_size, dtype=torch.float32).to(device)\n",
        "        elif labels is not None:\n",
        "            labels = labels.contiguous().view(-1, 1)\n",
        "            if labels.shape[0] != batch_size:\n",
        "                raise ValueError('Num of labels does not match num of features')\n",
        "            mask = torch.eq(labels, labels.T).float().to(device)\n",
        "        else:\n",
        "            mask = mask.float().to(device)\n",
        "\n",
        "        contrast_count = features.shape[1]\n",
        "        contrast_feature = torch.cat(torch.unbind(features, dim=1), dim=0)\n",
        "        if self.contrast_mode == 'one':\n",
        "            anchor_feature = features[:, 0]\n",
        "            anchor_count = 1\n",
        "        elif self.contrast_mode == 'all':\n",
        "            anchor_feature = contrast_feature\n",
        "            anchor_count = contrast_count\n",
        "        else:\n",
        "            raise ValueError('Unknown mode: {}'.format(self.contrast_mode))\n",
        "\n",
        "        # compute logits\n",
        "        anchor_dot_contrast = torch.div(\n",
        "            torch.matmul(anchor_feature, contrast_feature.T),\n",
        "            self.temperature)\n",
        "        # for numerical stability\n",
        "        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)\n",
        "        logits = anchor_dot_contrast - logits_max.detach()\n",
        "\n",
        "        # tile mask\n",
        "        mask = mask.repeat(anchor_count, contrast_count)\n",
        "        # mask-out self-contrast cases\n",
        "        logits_mask = torch.scatter(\n",
        "            torch.ones_like(mask),\n",
        "            1,\n",
        "            torch.arange(batch_size * anchor_count).view(-1, 1).to(device),\n",
        "            0\n",
        "        )\n",
        "        mask = mask * logits_mask\n",
        "\n",
        "        # compute log_prob\n",
        "        exp_logits = torch.exp(logits) * logits_mask\n",
        "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))\n",
        "\n",
        "        # compute mean of log-likelihood over positive\n",
        "        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)\n",
        "\n",
        "        # loss\n",
        "        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos\n",
        "        loss = loss.view(anchor_count, batch_size).mean()\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "vgtD5F3MXdYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will train the features part of the network with an unsupervised contrastive loss and then fine-tune the classifier."
      ],
      "metadata": {
        "id": "VZ8fcrgfYEZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feat_model = models.alexnet(num_classes=10).features\n",
        "feat_model"
      ],
      "metadata": {
        "id": "73HrQKo2XxzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select an appropriate lr and number of epochs\n",
        "epochs = 50\n",
        "criterion = SupConLoss()\n",
        "optimizer = optim.SGD(lr=0.001, weight_decay=5e-4, momentum=0.9)\n",
        "for e in range(epochs):\n",
        "    for idx, (images, labels) in enumerate(trainloader):\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        features = feat_model(images)\n",
        "        loss = criterion(features, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "GKzHtlPYYe8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.alexnet(num_classes=10)\n",
        "model.load_state_dict(feat_model.state_dict(), strict=False)\n",
        "for param in model.features.parameters():\n",
        "    param.require_grad=False"
      ],
      "metadata": {
        "id": "0G0aqjNUZsJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model on the classification task and compare the performance with previous experiments"
      ],
      "metadata": {
        "id": "dC_BHhUqZ2mT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here"
      ],
      "metadata": {
        "id": "vQvhmXshZ__3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. “ImageNet Classification with Deep Convolutional\n",
        "Neural Networks”, NIPS 2012\n",
        "\n",
        "[2] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. \"A simple framework for contrastive learning of visual representations.\" In International conference on machine learning. PMLR, 1597–1607. \n",
        "\n",
        "[3] Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey E Hinton. 2020. \"Big self-supervised models are strong semi-supervised learners.\" Advances in neural information processing systems 33 (2020), 22243–22255.\n",
        "\n",
        "[4] P. Khosla et al., \"Supervised Contrastive Learning\", in Advances in Neural Information Processing Systems, 2020, vol. 33, pp. 18661–18673."
      ],
      "metadata": {
        "id": "Ndj6_KaFrGLo"
      }
    }
  ]
}